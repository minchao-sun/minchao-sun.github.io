---
title: "Network Compression"
classes: #wide
mathjax: true
categories:
  - Machine Learning
---

如今模型参数量越来越多，但是在edge device或者推理的时候没有那么多的算力或是内存怎么办呢，这里介绍模型压缩的技术。

模型压缩大体上有这么些方式：

* Network Pruning
* Knowledge Distillation
* Parameter Quantization

 